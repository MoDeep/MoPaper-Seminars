# MoDeep Seminar-Paper-Lists

### Deep Learning Basics
1. [Adam : A Method for Stochastic Optimization - Kingma et al.](https://arxiv.org/pdf/1412.6980.pdf)
2. [Batch Normalization - Sergey et al.](https://arxiv.org/pdf/1502.03167.pdf)

### CNN / Image Recognition Models
1. [Visualizing and Understanding Convolutional Networks - Matthew et al.](https://arxiv.org/abs/1311.2901)
2. [Going Deeper with Convolutions - Szegedy et al.](https://arxiv.org/abs/1409.4842)
3. [Rethinking the Inception Architecture for Computer Vision - Szegedy et al.](https://arxiv.org/abs/1512.00567)
4. [Deep Residual Learning for Image Recognition - Kaiming et al.](https://arxiv.org/abs/1512.03385)
5. [ImageNet Classification with Deep Convolutional Neural Networks - Krizhevsky et al.](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)
6. [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567)
7. [Dynamic Routing Between Capsules - Sabour et al.](https://arxiv.org/pdf/1710.09829.pdf)
8. [Deep Visual-Semantic Alignments for Generating Image Descriptions - Karpathy et al.](https://arxiv.org/pdf/1412.2306v2.pdf)
9. [Spatial Transformer Networks - Max Jaderberg et al.](https://arxiv.org/pdf/1506.02025.pdf)


#### Style Transfer
1. [Understanding Deep Image Representations by Inverting Them - Mahendran](https://arxiv.org/abs/1412.0035)
2. [A Neural Algorithm of Artistic Style - Gatys](https://arxiv.org/abs/1508.06576)

### Object Detection Models
1. [Faster R-CNN - Shaoqing et al.](https://arxiv.org/pdf/1506.01497.pdf)
2. [You Only Look Once:Unified, Real-Time Object Detection, YOLO - Redmon et al.](https://arxiv.org/pdf/1506.02640.pdf)
3. [Fully Convolutional Networks for Semantic Segmentation - Long et al.](https://arxiv.org/pdf/1411.4038.pdf)
4. [SSD : Single Shot Multibox Detector - Liu et al.](https://arxiv.org/pdf/1512.02325.pdf)
5. [Deformable Convolutional Network - Dai et al.](https://arxiv.org/pdf/1703.06211.pdf)
6. [Mask R-CNN - He et al.](https://arxiv.org/pdf/1703.06870.pdf)
7. [Light-Head R-CNN : In Defense of Two-Stage Object Detector - Li et al.](https://arxiv.org/pdf/1711.07264.pdf)
8. [Focal Loss for Dense Object Detection - Lin et al.](https://arxiv.org/pdf/1708.02002.pdf)
9. [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications - Howard et al.](https://arxiv.org/pdf/1704.04861.pdf)

### Generative Models
1. [Auto-Encoding Variational Bayes - Kingma et al.](https://arxiv.org/pdf/1312.6114.pdf)
2. [Generative Adversarial Nets - Goodfellow et al.](https://arxiv.org/pdf/1406.2661.pdf)
3. [Deep Convolutional Generative Adversarial Networks - Alec et al.](https://arxiv.org/pdf/1511.06434.pdf)
4. [Conditional Generative Adversarial Nets - Mehdi et al.](https://arxiv.org/pdf/1411.1784.pdf)
5. [InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets - Chen et al.](https://arxiv.org/pdf/1606.03657.pdf)
6. [Image-to-Image Translation with Conditional Adversarial Networks - Phillip et al.](https://arxiv.org/pdf/1611.07004.pdf)
7. [Cycle-Consistent Adversarial Networks - Jun-Yan et al.](https://arxiv.org/pdf/1703.10593.pdf)
8. [StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation - Yunjey Choi et al.](https://arxiv.org/pdf/1711.09020.pdf) 
9. [Learning from Simulated and Unsupervised Images through Adversarial Training - Shrivastava et al.](https://arxiv.org/pdf/1612.07828.pdf)
10. [Are GANs create equal? A Large-Scale Study - Lucic et al.](https://arxiv.org/pdf/1711.10337.pdf)
11. [Energy-based Generative Adversarial Network - Zhao et al.](https://arxiv.org/pdf/1609.03126.pdf)
12. [Wasserstein GAN - Arjovsky et al.](https://arxiv.org/pdf/1701.07875.pdf)
13. [BEGAN: Boundary Equilibrium Generative Adversarial Networks - Berthelot et al.](https://arxiv.org/pdf/1703.10717.pdf)
14. [Pixel Recurrent Neural Networks - Oord et al.](https://arxiv.org/pdf/1601.06759v2.pdf)

### Speech Synthesis
1. [Tacotron: Towards End-to-End Speech Synthesis - Yuxuan Wang et al.](https://arxiv.org/abs/1703.10135)
2. [Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions - Jonathan Shen et al.](https://arxiv.org/abs/1712.05884)
3. [Deep Voice 2: Multi-Speaker Neural Text-to-Speech - Sercan Arik et al.](https://arxiv.org/abs/1705.08947)
4. [Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning - Wei Ping et al.](https://arxiv.org/abs/1710.07654)

### Mathmatics
1. [A Primer on Optima Transport in NIPS 2017 - Marco Cuturi](https://nips.cc/Conferences/2017/Schedule?showEvent=8736)

### Reinforcement Learnings
1. [Asynchronous Methods for Deep Reinforcement Learning - Mnih et al.](https://arxiv.org/abs/1602.01783)
2. [Playing Atari with Deep Reinforcement Learning - Mnih et al.](https://arxiv.org/abs/1312.5602)
x
### Sequencial Models / NLP
1. [Long Short-Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling - Hasim Sak et al.](https://static.googleusercontent.com/media/research.google.com/ko//pubs/archive/43905.pdf)
2. [Sequence to sequence learning with neural networks - Sutskever et al.](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)
3. [Very Deep Convolutional Networks for Text Classification - Conneau et al.](https://arxiv.org/pdf/1606.01781.pdf)
4. [Deep Learning applied to NLP - Marc Moreno Lopez et al.](https://arxiv.org/pdf/1703.03091.pdf)
5. [Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling - Junyoung Chung et al.](https://arxiv.org/abs/1412.3555)

### Tip / Tutorial Papers
1. [Awesome RNN](https://github.com/kjw0612/awesome-rnn)
2. [Awesome Public DataSets](https://github.com/awesomedata/awesome-public-datasets)
3. [NIPS tutorial - Generative Adversarial Networks(PDF/Video) - Ian Goodfellow](https://nips.cc/Conferences/2016/Schedule?showEvent=6202)  
4. [A guide to convolution arithmetic for deep learning - Vincent Dumoulin and Francesco Visin](https://arxiv.org/pdf/1603.07285.pdf)

### Writing Rules
1. 새로운 논문을 추가할 때는 다른 논문들과 규칙을 맞추어서 작성.
2. 되도록이면 논문의 PDF 파일을 하이퍼링크.
3. Alt Text는 '논문 제목 - 제 1저자' 형식 맞추어 작성.

### Repository References
1. [Deep Learning Papers Reading Loadmap](https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap)
2. [Awesome Deep Learning Papers](https://github.com/terryum/awesome-deep-learning-papers)
